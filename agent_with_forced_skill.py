# agent_with_forced_skill.py
import os
import re
import yaml
from pathlib import Path
from typing import TypedDict, Literal, Optional

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import HumanMessage
from langchain_openai import ChatOpenAI  # å¯æ›¿æ¢ä¸º Qwen / Ollama / DashScope
from langgraph.graph import StateGraph, END


# ----------------------------
# 1. Agent çŠ¶æ€å®šä¹‰ï¼ˆæ–°å¢ forced_skill å­—æ®µï¼‰
# ----------------------------
class AgentState(TypedDict):
    user_input: str
    forced_skill: Optional[str]          # ğŸ‘ˆ æ–°å¢ï¼šå¦‚æœé Noneï¼Œåˆ™è·³è¿‡è·¯ç”±
    selected_skill: Optional[str]
    final_response: Optional[str]


# ----------------------------
# 2. æœ¬åœ° Skill ç®¡ç†å™¨ï¼ˆä¸å˜ï¼‰
# ----------------------------
class LocalSkillManager:
    def __init__(self, skills_dir: str = "~/.local/skills"):
        self.skills_dir = Path(skills_dir).expanduser()
        self.skills = self._load_skills()

    def _load_skills(self):
        skills = {}
        for folder in self.skills_dir.iterdir():
            if folder.is_dir():
                skill_file = folder / "SKILL.md"
                if skill_file.exists():
                    try:
                        text = skill_file.read_text(encoding="utf-8")
                        match = re.match(r'^---\s*\n(.*?)\n---\s*\n', text, re.DOTALL)
                        if match:
                            meta = yaml.safe_load(match.group(1))
                            body = re.sub(r'^---\s*\n.*?\n---\s*\n', '', text, flags=re.DOTALL).strip()
                            skills[folder.name] = {
                                "name": meta.get("name", folder.name),
                                "description": meta.get("description", ""),
                                "instructions": body
                            }
                    except Exception as e:
                        print(f"âš ï¸ åŠ è½½æŠ€èƒ½ {folder.name} å¤±è´¥: {e}")
        return skills

    def get_instructions(self, skill_name: str) -> str:
        if skill_name not in self.skills:
            raise ValueError(f"æŠ€èƒ½ '{skill_name}' æœªåœ¨æœ¬åœ°æ‰¾åˆ°ï¼Œè¯·æ£€æŸ¥ ~/.local/skills/ ç›®å½•")
        return self.skills[skill_name]["instructions"]

    def list_skills(self):
        return list(self.skills.keys())


# ----------------------------
# 3. èŠ‚ç‚¹å‡½æ•°
# ----------------------------
skill_manager = LocalSkillManager()
# æ›¿æ¢ä¸ºä½ è‡ªå·±çš„æ¨¡å‹ï¼Œä¾‹å¦‚ Qwenï¼š
# from langchain_community.chat_models import ChatTongyi
# llm = ChatTongyi(model="qwen-max", temperature=0.7)
llm = ChatOpenAI(model="gpt-4o", temperature=0.7)


def decide_route_or_force(state: AgentState) -> Literal["execute_skill", "route_fallback"]:
    """
    åˆ¤æ–­æ˜¯å¼ºåˆ¶ä½¿ç”¨æŠ€èƒ½ï¼Œè¿˜æ˜¯èµ°è‡ªåŠ¨è·¯ç”±
    """
    if state.get("forced_skill"):
        # å¼ºåˆ¶æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨æŒ‡å®šæŠ€èƒ½
        state["selected_skill"] = state["forced_skill"]
        return "execute_skill"
    else:
        # è‡ªåŠ¨è·¯ç”±æ¨¡å¼ï¼šå°è¯•åŒ¹é…
        return "route_fallback"


def route_fallback(state: AgentState) -> Literal["execute_skill", "fallback"]:
    """è‡ªåŠ¨è·¯ç”±é€»è¾‘ï¼ˆä»…åœ¨æœªå¼ºåˆ¶æŒ‡å®šæ—¶è°ƒç”¨ï¼‰"""
    user_input = state["user_input"]
    skill_desc = "\n".join(
        f"- `{name}`: {info['description']}"
        for name, info in skill_manager.skills.items()
    )

    if not skill_desc:
        return "fallback"

    router_prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ˜¯ä¸€ä¸ª AI Agent çš„æŠ€èƒ½è·¯ç”±å™¨ã€‚è¯·æ ¹æ®ç”¨æˆ·è¯·æ±‚ï¼Œä»ä»¥ä¸‹å¯ç”¨æŠ€èƒ½ä¸­é€‰æ‹©æœ€åŒ¹é…çš„ä¸€ä¸ªã€‚\n\nå¯ç”¨æŠ€èƒ½ï¼š\n{skills}\n\nå¦‚æœéƒ½ä¸åŒ¹é…ï¼Œå›ç­” NONEã€‚"),
        ("user", "ç”¨æˆ·è¯·æ±‚ï¼š{input}\n\nè¯·åªè¾“å‡ºæŠ€èƒ½åç§°ï¼ˆå¦‚ xiaohongshuï¼‰æˆ– NONEï¼š")
    ])

    chain = router_prompt | llm
    response = chain.invoke({"skills": skill_desc, "input": user_input})
    selected = response.content.strip()

    if selected in skill_manager.skills:
        state["selected_skill"] = selected
        return "execute_skill"
    else:
        return "fallback"


def execute_skill(state: AgentState):
    skill_name = state["selected_skill"]
    instructions = skill_manager.get_instructions(skill_name)
    user_input = state["user_input"]

    prompt = ChatPromptTemplate.from_messages([
        ("system", "ä½ æ­£åœ¨ä½¿ç”¨ã€Œ{skill_name}ã€æŠ€èƒ½ã€‚è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹æ“ä½œè§„èŒƒï¼š\n\n{instructions}"),
        ("user", "{input}")
    ])

    chain = prompt | llm
    response = chain.invoke({
        "skill_name": skill_name,
        "instructions": instructions,
        "input": user_input
    })

    state["final_response"] = response.content
    return state


def fallback(state: AgentState):
    response = llm.invoke([HumanMessage(content=state["user_input"])])
    state["final_response"] = response.content
    return state


# ----------------------------
# 4. æ„å»º Graph
# ----------------------------
def build_graph():
    workflow = StateGraph(AgentState)

    workflow.add_node("decide_route_or_force", lambda s: s)
    workflow.add_node("route_fallback", route_fallback)
    workflow.add_node("execute_skill", execute_skill)
    workflow.add_node("fallback", fallback)

    workflow.set_entry_point("decide_route_or_force")

    workflow.add_conditional_edges(
        "decide_route_or_force",
        decide_route_or_force,
        {
            "execute_skill": "execute_skill",
            "route_fallback": "route_fallback"
        }
    )

    workflow.add_conditional_edges(
        "route_fallback",
        lambda s: s,  # ç›´æ¥è¿”å›å­—ç¬¦ä¸²åˆ†æ”¯
        {
            "execute_skill": "execute_skill",
            "fallback": "fallback"
        }
    )

    workflow.add_edge("execute_skill", END)
    workflow.add_edge("fallback", END)

    return workflow.compile()


# ----------------------------
# 5. ä½¿ç”¨ç¤ºä¾‹
# ----------------------------
if __name__ == "__main__":
    app = build_graph()

    # âœ… æ–¹å¼ 1ï¼šè‡ªåŠ¨è·¯ç”±
    print("ã€è‡ªåŠ¨è·¯ç”±ã€‘")
    result1 = app.invoke({
        "user_input": "å¸®æˆ‘å†™ä¸€ç¯‡å…³äºæŠ¤æ‰‹éœœçš„å°çº¢ä¹¦çˆ†æ¬¾æ–‡æ¡ˆ",
        "forced_skill": None,
        "selected_skill": None,
        "final_response": None
    })
    print(result1["final_response"])

    print("\n" + "="*60 + "\n")

    # âœ… æ–¹å¼ 2ï¼šå¼ºåˆ¶ä½¿ç”¨æŸä¸ª Skillï¼ˆå³ä½¿æè¿°ä¸åŒ¹é…ï¼‰
    print("ã€å¼ºåˆ¶ä½¿ç”¨ xiaohongshu æŠ€èƒ½ã€‘")
    result2 = app.invoke({
        "user_input": "æ€»ç»“ä¸€ä¸‹é‡å­åŠ›å­¦çš„åŸºæœ¬åŸç†",  # è¿™æ˜¾ç„¶ä¸æ˜¯å°çº¢ä¹¦åœºæ™¯
        "forced_skill": "xiaohongshu",               # ä½†å¼ºåˆ¶ç”¨å®ƒï¼
        "selected_skill": None,
        "final_response": None
    })
    print(result2["final_response"])
